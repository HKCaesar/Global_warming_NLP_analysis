{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The global warming issue and Narratives around it<br>\n",
    "### Part 4: Performing modeling on the pickled reddit dataset\n",
    "\n",
    "In this notebook, I set the stage for tnuning and scoring the following models:\n",
    "\n",
    "- **Logistic Regression** ---> only on vectorized text (bag of words: CountVectorizer<br><br>\n",
    "- **Naïve Bayes** ---> only on vectorized text, vectorized by CountVectorizer<br>\n",
    "- **Naïve Bayes** ---> only on vectorized text, vectorized by TF-IDF vectorizer<br><br>\n",
    "- **Random forest** ---> only on vectorized text, vectorized by CountVectorizer<br>\n",
    "- **Extra tress** ---> only on vectorized text, vectorized by CountVectorizer<br>\n",
    "- **GBoost** ---> only on vectorized text (using CountVectorizer)<br>\n",
    "- **Neural Network** ---> only on vectorized text (using CountVectorizer)<br>\n",
    "- **support vector machine (SVM)** ---> only on vectorized text (using CountVectorizer)<br>\n",
    "\n",
    "\n",
    "\n",
    "`- Note: In this notebook, we only studied the model performance on text douments to compare the models`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the require libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smighani/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/smighani/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import eli5\n",
    "\n",
    "import regex as re\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.1: Importing the saved dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>over_18</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>text_merged</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text_char_count</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kafka15</td>\n",
       "      <td>1593554514</td>\n",
       "      <td>hixbtf</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>image</td>\n",
       "      <td>1</td>\n",
       "      <td>6157.0</td>\n",
       "      <td>cum</td>\n",
       "      <td>GlobalWarming</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2020-06-30 22:01:54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>karan_negiiiii</td>\n",
       "      <td>1593497051</td>\n",
       "      <td>hihj6s</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Empty</td>\n",
       "      <td>1</td>\n",
       "      <td>6156.0</td>\n",
       "      <td>climat chang india</td>\n",
       "      <td>GlobalWarming</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2020-06-30 06:04:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hildavardr</td>\n",
       "      <td>1593479932</td>\n",
       "      <td>hidb5h</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Empty</td>\n",
       "      <td>1</td>\n",
       "      <td>6154.0</td>\n",
       "      <td>global warm respons big compani</td>\n",
       "      <td>GlobalWarming</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>2020-06-30 01:18:52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pEppapiGistfuhrer</td>\n",
       "      <td>1593455137</td>\n",
       "      <td>hi5h41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>image</td>\n",
       "      <td>1</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>ayi let stop global warm</td>\n",
       "      <td>GlobalWarming</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>2020-06-29 18:25:37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BrexitBlaze</td>\n",
       "      <td>1593455005</td>\n",
       "      <td>hi5feq</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>link</td>\n",
       "      <td>2</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>uk minist send mix messag climat commit say fu...</td>\n",
       "      <td>GlobalWarming</td>\n",
       "      <td>66</td>\n",
       "      <td>13</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>2020-06-29 18:23:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author  created_utc      id  num_comments  over_18 post_hint  \\\n",
       "0            Kafka15   1593554514  hixbtf             2        0     image   \n",
       "1     karan_negiiiii   1593497051  hihj6s             0        0     Empty   \n",
       "2         Hildavardr   1593479932  hidb5h             0        0     Empty   \n",
       "3  pEppapiGistfuhrer   1593455137  hi5h41             1        0     image   \n",
       "4        BrexitBlaze   1593455005  hi5feq             2        0      link   \n",
       "\n",
       "   score  subreddit_subscribers  \\\n",
       "0      1                 6157.0   \n",
       "1      1                 6156.0   \n",
       "2      1                 6154.0   \n",
       "3      1                 6152.0   \n",
       "4      2                 6152.0   \n",
       "\n",
       "                                         text_merged      subreddit  \\\n",
       "0                                                cum  GlobalWarming   \n",
       "1                                 climat chang india  GlobalWarming   \n",
       "2                    global warm respons big compani  GlobalWarming   \n",
       "3                           ayi let stop global warm  GlobalWarming   \n",
       "4  uk minist send mix messag climat commit say fu...  GlobalWarming   \n",
       "\n",
       "   text_char_count  text_word_count  sentiment_score                date  \\\n",
       "0                3                1           0.0000 2020-06-30 22:01:54   \n",
       "1               18                3           0.0000 2020-06-30 06:04:11   \n",
       "2               31                5           0.2263 2020-06-30 01:18:52   \n",
       "3               24                5          -0.0772 2020-06-29 18:25:37   \n",
       "4               66               13           0.2960 2020-06-29 18:23:25   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit = pickle.load(open('../datasets/df_reddit_for_model.pkl', 'rb'))\n",
    "df_reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4828, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapped the under-represented class to balance the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bts_sample = df_reddit[(df_reddit[\"subreddit\"]==\"GlobalWarming\")].shape[0] - df_reddit[(df_reddit[\"subreddit\"]==\"ConspiracyTheory\")].shape[0]\n",
    "\n",
    "df_btsp = df_reddit[(df_reddit[\"subreddit\"]==\"ConspiracyTheory\")].sample(n = n_bts_sample, replace=True, random_state=42)\n",
    "\n",
    "df_reddit_btsp = pd.concat([df_reddit, df_btsp])\n",
    "\n",
    "df_reddit_btsp.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining X and Y variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reddit_btsp['text_merged']\n",
    "y = df_reddit_btsp['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train/test split:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for stratified target variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.500085\n",
       "0    0.499915\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500254\n",
       "1    0.499746\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500254\n",
       "1    0.499746\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, 50%, this is the worst we are allowed to do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for more stop words by vectoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a stop word list which I derived from an initial plot:\n",
    "#list_stop_words = [\"dec\", \"http\", \"www\", \"chang\", \"com\"]\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             #ngram_range=(1,2),\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = None,\n",
    "                             max_features = 3000) \n",
    "\n",
    "\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "\n",
    "#X_test_features = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abducte</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absorb</th>\n",
       "      <th>abus</th>\n",
       "      <th>ac</th>\n",
       "      <th>accept</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtu</th>\n",
       "      <th>youtub</th>\n",
       "      <th>zag</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeu</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abduct  abducte  abil  abl  absolut  absorb  abus  ac  accept  \\\n",
       "0        0       0        0     0    0        0       0     0   0       0   \n",
       "1        0       0        0     0    0        0       0     0   0       0   \n",
       "\n",
       "   ...  younger  youth  youtu  youtub  zag  zealand  zero  zeu  zombi  zone  \n",
       "0  ...        0      0      0       0    0        0     0    0      0     0  \n",
       "1  ...        0      0      0       0    0        0     0    0      0     0  \n",
       "\n",
       "[2 rows x 3000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features_df = pd.DataFrame(X_train_features.toarray(),\n",
    "                          columns=vectorizer.get_feature_names())\n",
    "X_train_features_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into which words are used alot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global</td>\n",
       "      <td>1318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>warm</td>\n",
       "      <td>1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>climat</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>like</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peopl</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chang</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>would</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>us</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1\n",
       "0  global  1318\n",
       "1    warm  1231\n",
       "2   world  1117\n",
       "3    http  1018\n",
       "4  climat   962\n",
       "5    like   953\n",
       "6   peopl   891\n",
       "7   chang   888\n",
       "8   would   804\n",
       "9      us   783"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get count of top-occurring words\n",
    "\n",
    "# empty dictionary\n",
    "top_words = {}\n",
    "\n",
    "# loop through columns\n",
    "for i in X_train_features_df.columns:\n",
    "    # save sum of each column in dictionary\n",
    "    top_words[i] =  X_train_features_df[i].sum()\n",
    "    \n",
    "# top_words to dataframe sorted by highest occurance\n",
    "most_freq = pd.DataFrame(sorted(top_words.items(), key = lambda x: x[1], reverse = True))\n",
    "most_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "# visualize top 10 words\n",
    "plt.bar(most_freq[0][:10], most_freq[1][:10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To remove words !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stop_words = [\"dec\", \"global\", \"http\", \"www\", \"com\", \"conspiraci\", \"warm\", \"climat\", \"remov\", \"theori\", \"theactualshadow\", \"co\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.2- **Logistic Regression**\n",
    "## only on vectorized text (bag of words: CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing the pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__stop_words': [list_stop_words, 'english'],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9913573970513472"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9639044229791561"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "#plot_confusion_matrix(gs, X_test_features, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, running a base log-reg to look at the words that were important: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             #ngram_range=(1,2),\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = list_stop_words,\n",
    "                             max_features = 3000) \n",
    "\n",
    "\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "X_test_features = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train_features, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9774614472123369"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323843416370107"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe to look at the coefficient of the basae model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>LR_coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chang</td>\n",
       "      <td>2.701103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carbon</td>\n",
       "      <td>2.277294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scientist</td>\n",
       "      <td>2.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emiss</td>\n",
       "      <td>1.964167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>environment</td>\n",
       "      <td>1.907267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>moon</td>\n",
       "      <td>-2.058871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>illuminati</td>\n",
       "      <td>-2.123301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>assassin</td>\n",
       "      <td>-2.135199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>mandela</td>\n",
       "      <td>-2.440148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>alien</td>\n",
       "      <td>-2.650792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_names  LR_coefficients\n",
       "0            chang         2.701103\n",
       "1           carbon         2.277294\n",
       "2        scientist         2.004883\n",
       "3            emiss         1.964167\n",
       "4      environment         1.907267\n",
       "...            ...              ...\n",
       "2995          moon        -2.058871\n",
       "2996    illuminati        -2.123301\n",
       "2997      assassin        -2.135199\n",
       "2998       mandela        -2.440148\n",
       "2999         alien        -2.650792\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coeffs = pd.DataFrame()\n",
    "df_coef= pd.DataFrame(lr.coef_).T\n",
    "df_feat = pd.DataFrame(vectorizer.get_feature_names())\n",
    "\n",
    "df_lr_coefs=pd.concat([df_feat, df_coef], axis=1)\n",
    "df_lr_coefs.columns = [\"feature_names\", \"LR_coefficients\"]\n",
    "df_lr_coefs_sorted = df_lr_coefs.sort_values(by =[\"LR_coefficients\"], ascending=False, ignore_index=True)\n",
    "df_lr_coefs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>LR_coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chang</td>\n",
       "      <td>2.701103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carbon</td>\n",
       "      <td>2.277294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scientist</td>\n",
       "      <td>2.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emiss</td>\n",
       "      <td>1.964167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>environment</td>\n",
       "      <td>1.907267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>temperatur</td>\n",
       "      <td>1.851639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>futur</td>\n",
       "      <td>1.590890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ice</td>\n",
       "      <td>1.564098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hottest</td>\n",
       "      <td>1.491541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>environ</td>\n",
       "      <td>1.482627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_names  LR_coefficients\n",
       "0         chang         2.701103\n",
       "1        carbon         2.277294\n",
       "2     scientist         2.004883\n",
       "3         emiss         1.964167\n",
       "4   environment         1.907267\n",
       "5    temperatur         1.851639\n",
       "6         futur         1.590890\n",
       "7           ice         1.564098\n",
       "8       hottest         1.491541\n",
       "9       environ         1.482627"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr_coefs_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>LR_coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>epstein</td>\n",
       "      <td>-1.839416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>control</td>\n",
       "      <td>-1.848390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>dead</td>\n",
       "      <td>-1.859572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>iran</td>\n",
       "      <td>-2.003617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>ufo</td>\n",
       "      <td>-2.045038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>moon</td>\n",
       "      <td>-2.058871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>illuminati</td>\n",
       "      <td>-2.123301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>assassin</td>\n",
       "      <td>-2.135199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>mandela</td>\n",
       "      <td>-2.440148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>alien</td>\n",
       "      <td>-2.650792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_names  LR_coefficients\n",
       "2990       epstein        -1.839416\n",
       "2991       control        -1.848390\n",
       "2992          dead        -1.859572\n",
       "2993          iran        -2.003617\n",
       "2994           ufo        -2.045038\n",
       "2995          moon        -2.058871\n",
       "2996    illuminati        -2.123301\n",
       "2997      assassin        -2.135199\n",
       "2998       mandela        -2.440148\n",
       "2999         alien        -2.650792"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr_coefs_sorted.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr_coefs_sorted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.3- **Naïve Bayes** <br><br>(only on vectorized text, vectorized by CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Designing a pipeline for Bayes analysis to fine-tune the model and get best scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9405185561769192"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X_train, y_train, cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666158278257923"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466192170818505"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to tune over the CountVectorizer, we'll load our pipeline object into GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 90%, 95%\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9303520429397667\n"
     ]
    }
   ],
   "source": [
    "# What's the best score?\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9535671920013558"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9374682257244534"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "#plot_confusion_matrix(gs, X_test_features, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.4- **Naïve Bayes** <br><br>(only on vectorized text, vectorized by TF-IDF vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the transformer.\n",
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aacgtmjui</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aass</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbrevi</th>\n",
       "      <th>...</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorgt</th>\n",
       "      <th>zq</th>\n",
       "      <th>zr</th>\n",
       "      <th>ztiu</th>\n",
       "      <th>zuck</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zvhm</th>\n",
       "      <th>zwhvc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aacgtmjui  aaliyah  aaron  aass   ab  aback  abandon  abbott  abbrevi  \\\n",
       "0  0.0        0.0      0.0    0.0   0.0  0.0    0.0      0.0     0.0      0.0   \n",
       "1  0.0        0.0      0.0    0.0   0.0  0.0    0.0      0.0     0.0      0.0   \n",
       "2  0.0        0.0      0.0    0.0   0.0  0.0    0.0      0.0     0.0      0.0   \n",
       "3  0.0        0.0      0.0    0.0   0.0  0.0    0.0      0.0     0.0      0.0   \n",
       "4  0.0        0.0      0.0    0.0   0.0  0.0    0.0      0.0     0.0      0.0   \n",
       "\n",
       "   ...  zoo  zoom  zorgt   zq   zr  ztiu  zuck  zuckerberg  zvhm  zwhvc  \n",
       "0  ...  0.0   0.0    0.0  0.0  0.0   0.0   0.0         0.0   0.0    0.0  \n",
       "1  ...  0.0   0.0    0.0  0.0  0.0   0.0   0.0         0.0   0.0    0.0  \n",
       "2  ...  0.0   0.0    0.0  0.0  0.0   0.0   0.0         0.0   0.0    0.0  \n",
       "3  ...  0.0   0.0    0.0  0.0  0.0   0.0   0.0         0.0   0.0    0.0  \n",
       "4  ...  0.0   0.0    0.0  0.0  0.0   0.0   0.0         0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 9615 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tvec.fit_transform(X_train).toarray(),\n",
    "                  columns=tvec.get_feature_names())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Designing a pipeline for TF-IDF analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline with tf-idf vectorizer and multinomial naive bayes\n",
    "\n",
    "pipe_tvec = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# No stop words and english stop words\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_tvec_params = {\n",
    "    'tvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_tvec = GridSearchCV(pipe_tvec, # what object are we optimizing?\n",
    "                        param_grid = pipe_tvec_params, # what parameters values are we searching?\n",
    "                        cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs_tvec.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9674631418403661"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "gs_tvec.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9476359938993391"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "gs_tvec.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9634146341463414\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds_tvec = gs_tvec.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_tvec).ravel()\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "\n",
    "print('Specificity:', spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize this\n",
    "plt.figure(figsize=(20,16))\n",
    "\n",
    "plot_confusion_matrix(gs_tvec, X_test, y_test, cmap='Blues', values_format='d');\n",
    "plt.savefig(\"../plots/Confusion.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.5- **Random forest** <br> <br> (only on vectorized text, vectorized by CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9427223410209675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 200}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}\n",
    "gs = GridSearchCV(rf, param_grid=rf_params, cv=5)\n",
    "gs.fit(X_train_features, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923741738688358"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9598373157092018"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.6- **Extra tress** <br> <br> (only on vectorized text, vectorized by CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943739146658247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 200}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}\n",
    "gs = GridSearchCV(et, param_grid=rf_params, cv=5)\n",
    "gs.fit(X_train_features, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923741738688358"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649211997966446"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.7- **GBoost** <br> <br> only on vectorized text (using CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859345873580749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.12, 'max_depth': 4, 'n_estimators': 150}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "gboost_params = {\n",
    "    'max_depth': [2,3,4],\n",
    "    'n_estimators': [100, 125, 150],\n",
    "    'learning_rate': [.08, .1, .12]\n",
    "}\n",
    "gb_gs = GridSearchCV(gboost, param_grid=gboost_params, cv=3)\n",
    "gb_gs.fit(X_train_features, y_train)\n",
    "print(gb_gs.best_score_)\n",
    "gb_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9020504999152686"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_gs.score(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8530757498729029"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_gs.score(X_test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.8- **Neural Network** <br> <br> only on vectorized text (using CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(30, 30, 30))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923741738688358"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9400101677681749"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.9- **support vector machine (SVM)** <br> <br> only on vectorized text (using CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(\n",
    "    C = 100,\n",
    "    kernel = \"rbf\",\n",
    "    gamma = \"scale\"\n",
    ")\n",
    "\n",
    "# Fit on training data.\n",
    "svc.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9379766141331978"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model.\n",
    "accuracy_score(y_test, svc.predict(X_test_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
