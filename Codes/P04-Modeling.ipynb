{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The global warming issue and Narratives around it<br>\n",
    "### Part 4: Performing modeling on the pickled reddit dataset\n",
    "\n",
    "In this notebook, I set the stage for tnuning and scoring the following models:\n",
    "\n",
    "- **Logistic Regression** ---> only on vectorized text (bag of words: CountVectorizer<br><br>\n",
    "- **Naïve Bayes** ---> only on vectorized text, vectorized by CountVectorizer<br>\n",
    "- **Naïve Bayes** ---> only on vectorized text, vectorized by TF-IDF vectorizer<br><br>\n",
    "- **Random forest** ---> only on vectorized text, vectorized by CountVectorizer<br>\n",
    "- **Extra tress** ---> only on vectorized text, vectorized by CountVectorizer<br>\n",
    "- **GBoost** ---> only on vectorized text (using CountVectorizer)<br>\n",
    "- **Neural Network** ---> only on vectorized text (using CountVectorizer)<br>\n",
    "- **support vector machine (SVM)** ---> only on vectorized text (using CountVectorizer)<br>\n",
    "\n",
    "\n",
    "\n",
    "`- Note: In this notebook, we only studied the model performance on text douments to compare the models`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the require libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smighani/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/smighani/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import eli5\n",
    "\n",
    "import regex as re\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.1: Importing the saved dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>over_18</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>text_merged</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text_char_count</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kafka15</td>\n",
       "      <td>1593554514</td>\n",
       "      <td>hixbtf</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>image</td>\n",
       "      <td>1</td>\n",
       "      <td>6157.0</td>\n",
       "      <td>cum</td>\n",
       "      <td>GlobalWarming</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2020-06-30 22:01:54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>karan_negiiiii</td>\n",
       "      <td>1593497051</td>\n",
       "      <td>hihj6s</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Empty</td>\n",
       "      <td>1</td>\n",
       "      <td>6156.0</td>\n",
       "      <td>climat chang india</td>\n",
       "      <td>GlobalWarming</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2020-06-30 06:04:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hildavardr</td>\n",
       "      <td>1593479932</td>\n",
       "      <td>hidb5h</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Empty</td>\n",
       "      <td>1</td>\n",
       "      <td>6154.0</td>\n",
       "      <td>global warm respons big compani remov</td>\n",
       "      <td>GlobalWarming</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>2020-06-30 01:18:52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pEppapiGistfuhrer</td>\n",
       "      <td>1593455137</td>\n",
       "      <td>hi5h41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>image</td>\n",
       "      <td>1</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>ayi let stop global warm</td>\n",
       "      <td>GlobalWarming</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>2020-06-29 18:25:37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BrexitBlaze</td>\n",
       "      <td>1593455005</td>\n",
       "      <td>hi5feq</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>link</td>\n",
       "      <td>2</td>\n",
       "      <td>6152.0</td>\n",
       "      <td>uk minist send mix messag climat commit say fu...</td>\n",
       "      <td>GlobalWarming</td>\n",
       "      <td>66</td>\n",
       "      <td>13</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>2020-06-29 18:23:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author  created_utc      id  num_comments  over_18 post_hint  \\\n",
       "0            Kafka15   1593554514  hixbtf             2        0     image   \n",
       "1     karan_negiiiii   1593497051  hihj6s             0        0     Empty   \n",
       "2         Hildavardr   1593479932  hidb5h             0        0     Empty   \n",
       "3  pEppapiGistfuhrer   1593455137  hi5h41             1        0     image   \n",
       "4        BrexitBlaze   1593455005  hi5feq             2        0      link   \n",
       "\n",
       "   score  subreddit_subscribers  \\\n",
       "0      1                 6157.0   \n",
       "1      1                 6156.0   \n",
       "2      1                 6154.0   \n",
       "3      1                 6152.0   \n",
       "4      2                 6152.0   \n",
       "\n",
       "                                         text_merged      subreddit  \\\n",
       "0                                                cum  GlobalWarming   \n",
       "1                                 climat chang india  GlobalWarming   \n",
       "2              global warm respons big compani remov  GlobalWarming   \n",
       "3                           ayi let stop global warm  GlobalWarming   \n",
       "4  uk minist send mix messag climat commit say fu...  GlobalWarming   \n",
       "\n",
       "   text_char_count  text_word_count  sentiment_score                date  \\\n",
       "0                3                1           0.0000 2020-06-30 22:01:54   \n",
       "1               18                3           0.0000 2020-06-30 06:04:11   \n",
       "2               37                6           0.2263 2020-06-30 01:18:52   \n",
       "3               24                5          -0.0772 2020-06-29 18:25:37   \n",
       "4               66               13           0.2960 2020-06-29 18:23:25   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit = pickle.load(open('../datasets/df_reddit_for_model.pkl', 'rb'))\n",
    "df_reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4828, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapped the under-represented class to balance the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bts_sample = df_reddit[(df_reddit[\"subreddit\"]==\"GlobalWarming\")].shape[0] - df_reddit[(df_reddit[\"subreddit\"]==\"ConspiracyTheory\")].shape[0]\n",
    "\n",
    "df_btsp = df_reddit[(df_reddit[\"subreddit\"]==\"ConspiracyTheory\")].sample(n = n_bts_sample, replace=True, random_state=42)\n",
    "\n",
    "df_reddit_btsp = pd.concat([df_reddit, df_btsp])\n",
    "\n",
    "df_reddit_btsp.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining X and Y variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reddit_btsp['text_merged']\n",
    "y = df_reddit_btsp['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train/test split:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for stratified target variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.500085\n",
       "0    0.499915\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500254\n",
       "1    0.499746\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500254\n",
       "1    0.499746\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, 50%, this is the worst we are allowed to do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for more stop words by vectoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a stop word list which I derived from an initial plot:\n",
    "#list_stop_words = [\"dec\", \"http\", \"www\", \"chang\", \"com\"]\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             #ngram_range=(1,2),\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = None,\n",
    "                             max_features = 3000) \n",
    "\n",
    "\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "\n",
    "#X_test_features = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abducte</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absorb</th>\n",
       "      <th>abus</th>\n",
       "      <th>ac</th>\n",
       "      <th>accept</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtu</th>\n",
       "      <th>youtub</th>\n",
       "      <th>zag</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeu</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abduct  abducte  abil  abl  absolut  absorb  abus  ac  accept  \\\n",
       "0        0       0        0     0    0        0       0     0   0       0   \n",
       "1        0       0        0     0    0        0       0     0   0       0   \n",
       "\n",
       "   ...  younger  youth  youtu  youtub  zag  zealand  zero  zeu  zombi  zone  \n",
       "0  ...        0      0      0       0    0        0     0    0      0     0  \n",
       "1  ...        0      0      0       0    0        0     0    0      0     0  \n",
       "\n",
       "[2 rows x 3000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features_df = pd.DataFrame(X_train_features.toarray(),\n",
    "                          columns=vectorizer.get_feature_names())\n",
    "X_train_features_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into which words are used alot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global</td>\n",
       "      <td>1318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>warm</td>\n",
       "      <td>1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>climat</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>like</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peopl</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chang</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>would</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>us</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1\n",
       "0  global  1318\n",
       "1    warm  1231\n",
       "2   world  1117\n",
       "3    http  1018\n",
       "4  climat   962\n",
       "5    like   953\n",
       "6   peopl   891\n",
       "7   chang   888\n",
       "8   would   804\n",
       "9      us   783"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get count of top-occurring words\n",
    "\n",
    "# empty dictionary\n",
    "top_words = {}\n",
    "\n",
    "# loop through columns\n",
    "for i in X_train_features_df.columns:\n",
    "    # save sum of each column in dictionary\n",
    "    top_words[i] =  X_train_features_df[i].sum()\n",
    "    \n",
    "# top_words to dataframe sorted by highest occurance\n",
    "most_freq = pd.DataFrame(sorted(top_words.items(), key = lambda x: x[1], reverse = True))\n",
    "most_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "# visualize top 10 words\n",
    "plt.bar(most_freq[0][:10], most_freq[1][:10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To remove words !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stop_words = [\"dec\", \"global\", \"http\", \"www\", \"com\", \"conspiraci\", \"warm\", \"climat\", \"remov\", \"theori\", \"theactualshadow\", \"co\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.2- **Logistic Regression**\n",
    "## only on vectorized text (bag of words: CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing the pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__stop_words': [list_stop_words, 'english'],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990849008642603"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9603457041179461"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "#plot_confusion_matrix(gs, X_test_features, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, running a base log-reg to look at the words that were important: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             #ngram_range=(1,2),\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = list_stop_words,\n",
    "                             max_features = 3000) \n",
    "\n",
    "\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "X_test_features = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train_features, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9774614472123369"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323843416370107"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe to look at the coefficient of the basae model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>LR_coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chang</td>\n",
       "      <td>2.701103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carbon</td>\n",
       "      <td>2.277294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scientist</td>\n",
       "      <td>2.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emiss</td>\n",
       "      <td>1.964167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>environment</td>\n",
       "      <td>1.907267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>moon</td>\n",
       "      <td>-2.058871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>illuminati</td>\n",
       "      <td>-2.123301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>assassin</td>\n",
       "      <td>-2.135199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>mandela</td>\n",
       "      <td>-2.440148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>alien</td>\n",
       "      <td>-2.650792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_names  LR_coefficients\n",
       "0            chang         2.701103\n",
       "1           carbon         2.277294\n",
       "2        scientist         2.004883\n",
       "3            emiss         1.964167\n",
       "4      environment         1.907267\n",
       "...            ...              ...\n",
       "2995          moon        -2.058871\n",
       "2996    illuminati        -2.123301\n",
       "2997      assassin        -2.135199\n",
       "2998       mandela        -2.440148\n",
       "2999         alien        -2.650792\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coeffs = pd.DataFrame()\n",
    "df_coef= pd.DataFrame(lr.coef_).T\n",
    "df_feat = pd.DataFrame(vectorizer.get_feature_names())\n",
    "\n",
    "df_lr_coefs=pd.concat([df_feat, df_coef], axis=1)\n",
    "df_lr_coefs.columns = [\"feature_names\", \"LR_coefficients\"]\n",
    "df_lr_coefs_sorted = df_lr_coefs.sort_values(by =[\"LR_coefficients\"], ascending=False, ignore_index=True)\n",
    "df_lr_coefs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>LR_coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chang</td>\n",
       "      <td>2.701103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>carbon</td>\n",
       "      <td>2.277294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scientist</td>\n",
       "      <td>2.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emiss</td>\n",
       "      <td>1.964167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>environment</td>\n",
       "      <td>1.907267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>temperatur</td>\n",
       "      <td>1.851639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>futur</td>\n",
       "      <td>1.590890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ice</td>\n",
       "      <td>1.564098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hottest</td>\n",
       "      <td>1.491541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>environ</td>\n",
       "      <td>1.482627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_names  LR_coefficients\n",
       "0         chang         2.701103\n",
       "1        carbon         2.277294\n",
       "2     scientist         2.004883\n",
       "3         emiss         1.964167\n",
       "4   environment         1.907267\n",
       "5    temperatur         1.851639\n",
       "6         futur         1.590890\n",
       "7           ice         1.564098\n",
       "8       hottest         1.491541\n",
       "9       environ         1.482627"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr_coefs_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names</th>\n",
       "      <th>LR_coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>epstein</td>\n",
       "      <td>-1.839416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>control</td>\n",
       "      <td>-1.848390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>dead</td>\n",
       "      <td>-1.859572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>iran</td>\n",
       "      <td>-2.003617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>ufo</td>\n",
       "      <td>-2.045038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>moon</td>\n",
       "      <td>-2.058871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>illuminati</td>\n",
       "      <td>-2.123301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>assassin</td>\n",
       "      <td>-2.135199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>mandela</td>\n",
       "      <td>-2.440148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>alien</td>\n",
       "      <td>-2.650792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_names  LR_coefficients\n",
       "2990       epstein        -1.839416\n",
       "2991       control        -1.848390\n",
       "2992          dead        -1.859572\n",
       "2993          iran        -2.003617\n",
       "2994           ufo        -2.045038\n",
       "2995          moon        -2.058871\n",
       "2996    illuminati        -2.123301\n",
       "2997      assassin        -2.135199\n",
       "2998       mandela        -2.440148\n",
       "2999         alien        -2.650792"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr_coefs_sorted.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr_coefs_sorted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.3- **Naïve Bayes** <br><br>(only on vectorized text, vectorized by CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Designing a pipeline for Bayes analysis to fine-tune the model and get best scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9456024402643619"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X_train, y_train, cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.970344009489917"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9486527707168276"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to tune over the CountVectorizer, we'll load our pipeline object into GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 90%, 95%\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9345881829532571\n"
     ]
    }
   ],
   "source": [
    "# What's the best score?\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581426876800543"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415353329944077"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "#plot_confusion_matrix(gs, X_test_features, y_test, cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.4- **Naïve Bayes** <br><br>(only on vectorized text, vectorized by TF-IDF vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the transformer.\n",
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aacgtmjui</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aass</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbrevi</th>\n",
       "      <th>...</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorgt</th>\n",
       "      <th>zq</th>\n",
       "      <th>zr</th>\n",
       "      <th>ztiu</th>\n",
       "      <th>zuck</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zvhm</th>\n",
       "      <th>zwhvc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aacgtmjui  aaliyah  aaron  aass   ab  aback  abandon  abbott  abbrevi  \\\n",
       "0  0.0        0.0      0.0    0.0   0.0  0.0    0.0      0.0     0.0      0.0   \n",
       "1  0.0        0.0      0.0    0.0   0.0  0.0    0.0      0.0     0.0      0.0   \n",
       "2  0.0        0.0      0.0    0.0   0.0  0.0    0.0      0.0     0.0      0.0   \n",
       "3  0.0        0.0      0.0    0.0   0.0  0.0    0.0      0.0     0.0      0.0   \n",
       "4  0.0        0.0      0.0    0.0   0.0  0.0    0.0      0.0     0.0      0.0   \n",
       "\n",
       "   ...  zoo  zoom  zorgt   zq   zr  ztiu  zuck  zuckerberg  zvhm  zwhvc  \n",
       "0  ...  0.0   0.0    0.0  0.0  0.0   0.0   0.0         0.0   0.0    0.0  \n",
       "1  ...  0.0   0.0    0.0  0.0  0.0   0.0   0.0         0.0   0.0    0.0  \n",
       "2  ...  0.0   0.0    0.0  0.0  0.0   0.0   0.0         0.0   0.0    0.0  \n",
       "3  ...  0.0   0.0    0.0  0.0  0.0   0.0   0.0         0.0   0.0    0.0  \n",
       "4  ...  0.0   0.0    0.0  0.0  0.0   0.0   0.0         0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 9615 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tvec.fit_transform(X_train).toarray(),\n",
    "                  columns=tvec.get_feature_names())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Designing a pipeline for TF-IDF analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline with tf-idf vectorizer and multinomial naive bayes\n",
    "\n",
    "pipe_tvec = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 2000, 3000, 4000, 5000\n",
    "# No stop words and english stop words\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_tvec_params = {\n",
    "    'tvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_tvec = GridSearchCV(pipe_tvec, # what object are we optimizing?\n",
    "                        param_grid = pipe_tvec_params, # what parameters values are we searching?\n",
    "                        cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs_tvec.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.969666158278258"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "gs_tvec.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951194712760549"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "gs_tvec.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.967479674796748\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds_tvec = gs_tvec.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds_tvec).ravel()\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "\n",
    "print('Specificity:', spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize this\n",
    "plt.figure(figsize=(20,16))\n",
    "\n",
    "plot_confusion_matrix(gs_tvec, X_test, y_test, cmap='Blues', values_format='d');\n",
    "plt.savefig(\"../plots/Confusion.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.5- **Random forest** <br> <br> (only on vectorized text, vectorized by CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9408582212718324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 150}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}\n",
    "gs = GridSearchCV(rf, param_grid=rf_params, cv=5)\n",
    "gs.fit(X_train_features, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923741738688358"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9578037620742247"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.6- **Extra tress** <br> <br> (only on vectorized text, vectorized by CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9442477647497812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 200}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "}\n",
    "gs = GridSearchCV(et, param_grid=rf_params, cv=5)\n",
    "gs.fit(X_train_features, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923741738688358"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9644128113879004"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.7- **GBoost** <br> <br> only on vectorized text (using CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8605321132011524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.12, 'max_depth': 4, 'n_estimators': 150}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "gboost_params = {\n",
    "    'max_depth': [2,3,4],\n",
    "    'n_estimators': [100, 125, 150],\n",
    "    'learning_rate': [.08, .1, .12]\n",
    "}\n",
    "gb_gs = GridSearchCV(gboost, param_grid=gboost_params, cv=3)\n",
    "gb_gs.fit(X_train_features, y_train)\n",
    "print(gb_gs.best_score_)\n",
    "gb_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057786815793933"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_gs.score(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8591764107778342"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_gs.score(X_test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.8- **Neural Network** <br> <br> only on vectorized text (using CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(30, 30, 30))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9923741738688358"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9496695475343162"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.9- **support vector machine (SVM)** <br> <br> only on vectorized text (using CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(\n",
    "    C = 100,\n",
    "    kernel = \"rbf\",\n",
    "    gamma = \"scale\"\n",
    ")\n",
    "\n",
    "# Fit on training data.\n",
    "svc.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9379766141331978"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model.\n",
    "accuracy_score(y_test, svc.predict(X_test_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
