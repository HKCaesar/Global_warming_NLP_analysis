{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The global warming issue and Narratives around it<br>\n",
    "### Part 1: Pulling data from web API using pushshift\n",
    "\n",
    "In this notebook, I imported the posts from the following subreddits: <br><br>\n",
    "    1- [Globalwarming](https://www.reddit.com/r/GlobalWarming/) >: With 6.2k subscribers (Created on May 28, 2008). <br><br>\n",
    "    2- [Conspiracytheory](https://www.reddit.com/r/ConspiracyTheory/) : with 3.7k subscribers (Created on Dec 11, 2009). <br><br>\n",
    "    \n",
    "- **Problem statement:** The reddit users in **[Globalwarming]** subreddit were in general concerned, while the subreddit users in **[Conspiracytheory]** reddit were more interested in raising conspiracy theories. This contrasting viewpoint may be a good binary class target for our NLP analysis, to develop a trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The imported posts were converted to DataFrame and later saved into \"../datasets\" folder for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required libraries:\n",
    "\n",
    "- Built a general function to read reddit APIs: \"get_reddit_posts.py\"<br>\n",
    "    (\"Pushshift API\" serves the purpose in pulling the reddit posts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#Importing the built function, prior to that added the assets path to the system path\n",
    "#Inspiration: https://stackoverflow.com/questions/4383571/importing-files-from-different-folder\n",
    "\n",
    "import sys\n",
    "# inserting the parent directory into current path\n",
    "sys.path.insert(1, '../assets')\n",
    "\n",
    "from get_reddit_posts import get_reddit_posts\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1. Reading in the Global warming API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling in the created function and reading global warming data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 posts downloaded, oldest post:2020-04-28 16:58:48 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2020-03-03 03:02:47 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2020-01-23 13:16:14 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2020-01-02 05:23:33 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-11-26 18:31:35 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-10-20 17:46:56 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-09-24 10:26:43 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-08-30 12:20:26 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-08-05 20:18:37 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-07-17 10:44:37 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-06-14 23:18:29 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-05-08 15:28:20 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-03-23 08:00:14 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-02-01 08:29:10 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2018-11-24 14:58:45 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2018-09-24 18:05:36 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2018-07-05 07:42:01 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2018-03-01 04:08:25 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2017-12-13 10:03:48 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2017-09-16 09:01:50 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2017-06-29 16:25:22 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2017-05-04 00:27:43 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2017-02-22 06:17:37 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2016-12-26 06:47:14 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2016-10-18 18:29:52 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2016-05-30 13:48:06 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2016-03-19 23:49:16 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2015-12-14 06:28:56 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2015-09-22 19:55:04 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2015-06-12 11:01:58 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2015-03-20 19:01:19 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2014-11-16 18:22:03 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2014-08-15 16:10:54 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2014-05-27 06:58:26 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2014-02-23 08:32:27 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2013-11-24 10:02:24 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2013-06-23 17:20:32 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2012-11-23 11:21:34 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2012-02-29 02:09:35 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2008-10-12 01:44:26 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "\u001b[92m Does the imported dataframe match the request? False\u001b[00m\n",
      "Final DataFrame shape: (3934, 92), there are 0 duplicates\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Defining API pull initial parameteres:\n",
    "\n",
    "par = {\"subreddit\": \"GlobalWarming\", #The subreddit title\n",
    "       \"post_num\": 4000, # Numer of posts to pull from\n",
    "        \"time_1\": int(time.mktime(time.strptime('1 July, 2020', '%d %B, %Y'))), # The latest pull time\n",
    "       \"API_limit\": 100, # API pull number limits for reddit per time\n",
    "       \"API_wait\": 1 #API wait time berfore the next pull\n",
    "      }\n",
    "\n",
    "\n",
    "\n",
    "climate_change = get_reddit_posts(par[\"subreddit\"], par[\"post_num\"], par[\"time_1\"], par[ \"API_limit\"], par[\"API_wait\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>...</th>\n",
       "      <th>author_id</th>\n",
       "      <th>brand_safe</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>banned_at_utc</th>\n",
       "      <th>suggested_sort</th>\n",
       "      <th>view_count</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>mod_reports</th>\n",
       "      <th>user_reports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Kafka15</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_2hd4z3br</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>karan_negiiiii</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_5e3k31xp</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Hildavardr</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_73p53o6w</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>pEppapiGistfuhrer</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_41l09klf</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>BrexitBlaze</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_2v56rgmf</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings allow_live_comments             author author_flair_css_class  \\\n",
       "0            []               False            Kafka15                   None   \n",
       "1            []               False     karan_negiiiii                   None   \n",
       "2            []               False         Hildavardr                   None   \n",
       "3            []               False  pEppapiGistfuhrer                   None   \n",
       "4            []               False        BrexitBlaze                   None   \n",
       "\n",
       "  author_flair_richtext author_flair_text author_flair_type author_fullname  \\\n",
       "0                    []              None              text     t2_2hd4z3br   \n",
       "1                    []              None              text     t2_5e3k31xp   \n",
       "2                    []              None              text     t2_73p53o6w   \n",
       "3                    []              None              text     t2_41l09klf   \n",
       "4                    []              None              text     t2_2v56rgmf   \n",
       "\n",
       "  author_patreon_flair author_premium  ... author_id brand_safe  \\\n",
       "0                False          False  ...       NaN        NaN   \n",
       "1                False          False  ...       NaN        NaN   \n",
       "2                False          False  ...       NaN        NaN   \n",
       "3                False          False  ...       NaN        NaN   \n",
       "4                False           True  ...       NaN        NaN   \n",
       "\n",
       "  approved_at_utc  banned_at_utc suggested_sort view_count author_created_utc  \\\n",
       "0             NaN            NaN            NaN        NaN                NaN   \n",
       "1             NaN            NaN            NaN        NaN                NaN   \n",
       "2             NaN            NaN            NaN        NaN                NaN   \n",
       "3             NaN            NaN            NaN        NaN                NaN   \n",
       "4             NaN            NaN            NaN        NaN                NaN   \n",
       "\n",
       "  distinguished mod_reports user_reports  \n",
       "0           NaN         NaN          NaN  \n",
       "1           NaN         NaN          NaN  \n",
       "2           NaN         NaN          NaN  \n",
       "3           NaN         NaN          NaN  \n",
       "4           NaN         NaN          NaN  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_change.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3934, 92)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_change.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataframe into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/\" + par[\"subreddit\"] + \"_raw\" + \".csv\"\n",
    "climate_change.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2. Reading in the ConspiracyTheory API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling in the created function and reading conspiracyTheory data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 posts downloaded, oldest post:2019-11-12 15:09:47 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-09-02 20:00:45 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-07-14 17:57:30 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-05-28 07:49:16 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2019-03-16 17:29:32 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2018-08-10 14:35:41 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2017-11-10 06:12:43 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2015-08-25 11:30:25 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "100 posts downloaded, oldest post:2012-08-09 09:49:28 - status code: 200, now waiting 1 seconds before next pull. Patience...\n",
      "\u001b[92m Does the imported dataframe match the request? False\u001b[00m\n",
      "Final DataFrame shape: (894, 86), there are 0 duplicates\n"
     ]
    }
   ],
   "source": [
    "#Defining API pull initial parameteres:\n",
    "\n",
    "par = {\"subreddit\": \"ConspiracyTheory\", #The subreddit title\n",
    "       \"post_num\": 900, # Numer of posts to pull from (limited reddit)\n",
    "        \"time_1\": int(time.mktime(time.strptime('1 July, 2020', '%d %B, %Y'))), # The latest pull time\n",
    "       \"API_limit\": 100, # API pull number limits for reddit per time\n",
    "       \"API_wait\": 1 #API wait time berfore the next pull\n",
    "      }\n",
    "\n",
    "\n",
    "\n",
    "cons_theory = get_reddit_posts(par[\"subreddit\"], par[\"post_num\"], par[\"time_1\"], par[ \"API_limit\"], par[\"API_wait\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>...</th>\n",
       "      <th>banned_at_utc</th>\n",
       "      <th>parent_whitelist_status</th>\n",
       "      <th>suggested_sort</th>\n",
       "      <th>view_count</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>mod_reports</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>distinguished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>LonelyHampster</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_30uaspqv</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Switchkillengaged</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_wgxq1f6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>makiababi</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_1getuotr</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Raven9nine9</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_1g7arfuy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>finnagains</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_14267pk</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings allow_live_comments             author author_flair_css_class  \\\n",
       "0            []               False     LonelyHampster                   None   \n",
       "1            []               False  Switchkillengaged                   None   \n",
       "2            []               False          makiababi                   None   \n",
       "3            []               False        Raven9nine9                   None   \n",
       "4            []               False         finnagains                   None   \n",
       "\n",
       "  author_flair_richtext author_flair_text author_flair_type author_fullname  \\\n",
       "0                    []              None              text     t2_30uaspqv   \n",
       "1                    []              None              text      t2_wgxq1f6   \n",
       "2                    []              None              text     t2_1getuotr   \n",
       "3                    []              None              text     t2_1g7arfuy   \n",
       "4                    []              None              text      t2_14267pk   \n",
       "\n",
       "  author_patreon_flair author_premium  ... banned_at_utc  \\\n",
       "0                False          False  ...           NaN   \n",
       "1                False          False  ...           NaN   \n",
       "2                False          False  ...           NaN   \n",
       "3                False          False  ...           NaN   \n",
       "4                False          False  ...           NaN   \n",
       "\n",
       "  parent_whitelist_status suggested_sort  view_count whitelist_status  \\\n",
       "0                     NaN            NaN         NaN              NaN   \n",
       "1                     NaN            NaN         NaN              NaN   \n",
       "2                     NaN            NaN         NaN              NaN   \n",
       "3                     NaN            NaN         NaN              NaN   \n",
       "4                     NaN            NaN         NaN              NaN   \n",
       "\n",
       "  author_created_utc banned_by mod_reports user_reports distinguished  \n",
       "0                NaN       NaN         NaN          NaN           NaN  \n",
       "1                NaN       NaN         NaN          NaN           NaN  \n",
       "2                NaN       NaN         NaN          NaN           NaN  \n",
       "3                NaN       NaN         NaN          NaN           NaN  \n",
       "4                NaN       NaN         NaN          NaN           NaN  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_theory.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(894, 86)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_theory.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataframe into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../datasets/\" + par[\"subreddit\"] + \"_raw\" + \".csv\"\n",
    "cons_theory.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the data is ready for the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
